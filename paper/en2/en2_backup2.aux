\relax 
\citation{dobre2007survey}
\citation{hameed2009likelihood}
\citation{hazza2013overview}
\citation{oshea2016convolutional}
\citation{west2017deep,rajendran2018deep}
\citation{xu2025ldcvnn}
\citation{ma2023hfecnetca}
\citation{zhang2023efficient}
\citation{hazza2013overview}
\citation{oshea2016convolutional}
\citation{west2017deep,patil2021automatic}
\citation{rajendran2018deep,xu2020spatiotemporal}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Work}{1}{}\protected@file@percent }
\citation{xu2025ldcvnn}
\citation{ma2023hfecnetca}
\citation{guo2024ulcnn,ma2023hfecnetca,xu2025ldcvnn}
\citation{ning2024abftnet}
\citation{zhang2023amcnet}
\citation{zhang2023amcnet}
\citation{zhang2023amcnet}
\citation{yao2019modulation}
\citation{zhang2023efficient}
\@writefile{toc}{\contentsline {section}{\numberline {III}Methodology}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}Signal Mathematical Model}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}Dataset and Preprocessing}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-C}}Gaussian Process Regression Denoising}{3}{}\protected@file@percent }
\newlabel{eq:sigma_n_calc}{{\mbox  {III-C}}{3}{}{}{}}
\citation{guo2024ulcnn}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Complete data processing pipeline. This figure illustrates the entire workflow from raw I/Q signal input to final classification output, including GPR denoising, rotational data augmentation, and complex convolutional residual network processing stages.}}{4}{}\protected@file@percent }
\newlabel{fig:data_pipeline}{{1}{4}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-D}}Rotation-based Data Augmentation}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-E}}Hybrid ComplexCNN-ResNet Architecture}{4}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Constellation diagrams for 11 modulation types. This figure shows the signal point distribution of each modulation scheme in the I/Q plane, the rotational symmetry of which is the basis for the rotational data augmentation strategy adopted in this study.}}{5}{}\protected@file@percent }
\newlabel{fig:constellation}{{2}{5}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Detailed architecture of the hybrid ComplexCNN-ResNet. This figure shows the complete data flow from complex input to final classification output, including complex convolutional layers, ModReLU activation function, complex residual blocks, attention mechanism, and the complex-to-real conversion process.}}{6}{}\protected@file@percent }
\newlabel{fig:enhanced_hybrid_model}{{3}{6}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Processing flow of the hybrid ComplexCNN-ResNet architecture. This figure presents a block diagram illustrating the complete processing flow from I/Q signal input, complex feature extraction, residual learning, to final modulation classification, clearly depicting the data flow and processing logic between modules.}}{6}{}\protected@file@percent }
\newlabel{fig:lightweight_hybrid_model_flow}{{4}{6}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experimental Setup}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-A}}Training Configuration}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-B}}Evaluation Metrics}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {V}Results and Analysis}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-A}}Baseline Performance Comparison}{7}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Baseline Model Performance Comparison}}{7}{}\protected@file@percent }
\newlabel{tab:baseline_comparison}{{I}{7}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Performance comparison of different models under various SNR conditions. The figure shows the classification accuracy curves of five models (CNN1D, ResNet, ComplexCNN, Hybrid Architecture, Hybrid Architecture+GPR+Augmentation) under different signal-to-noise ratio conditions.}}{7}{}\protected@file@percent }
\newlabel{fig:snr_performance}{{5}{7}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Performance comparison analysis of different model architectures. This figure presents a comprehensive comparison of the hybrid architecture with traditional baseline models on key metrics such as classification accuracy, number of model parameters, and inference time.}}{7}{}\protected@file@percent }
\newlabel{fig:model_comparison}{{6}{7}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-B}}Impact of Gaussian Process Regression Denoising}{7}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Impact of GPR Denoising on Different SNR Ranges}}{8}{}\protected@file@percent }
\newlabel{tab:gpr_impact}{{II}{8}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Denoising effect on the constellation diagram of CPFSK modulation type under SNR conditions of 0 to 8dB.}}{8}{}\protected@file@percent }
\newlabel{fig:constellation_denoising}{{7}{8}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-C}}Effect of Rotation-based Data Augmentation}{8}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Detailed Impact of GPR Denoising at Various SNR Levels}}{8}{}\protected@file@percent }
\newlabel{tab:gpr_detailed_snr}{{III}{8}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces Impact of Data Augmentation on Various Modulation Types}}{8}{}\protected@file@percent }
\newlabel{tab:data_augmentation_results}{{IV}{8}{}{}{}}
\citation{xu2025ldcvnn}
\citation{guo2024ulcnn}
\citation{zhang2023amcnet}
\citation{ma2023hfecnetca}
\citation{ning2024abftnet}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces I/Q channel plot and constellation diagram for QAM16 signal.}}{9}{}\protected@file@percent }
\newlabel{fig:rotation_augmentation}{{8}{9}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-D}}Hybrid Architecture Performance}{9}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {V}{\ignorespaces Performance Comparison of Hybrid Architecture with Existing Methods}}{9}{}\protected@file@percent }
\newlabel{tab:hybrid_performance}{{V}{9}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Comprehensive performance comparison analysis of different methods. This figure displays the performance of various technical solutions sorted by classification accuracy, clearly reflecting the superiority of the comprehensive method proposed in this study.}}{9}{}\protected@file@percent }
\newlabel{fig:method_comparison}{{9}{9}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Comparison of validation accuracy convergence curves for various models. This figure shows the change in validation accuracy with training epochs for several baseline models, the proposed hybrid architecture, and its final optimized version (GRCR-Net, Proposed). The proposed GRCR-Net model not only achieves the highest validation accuracy but also exhibits fast and stable convergence characteristics.}}{9}{}\protected@file@percent }
\newlabel{fig:training_convergence}{{10}{9}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-E}}Ablation Study}{10}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {VI}{\ignorespaces Ablation Study Results (with Hybrid Architecture as Baseline)}}{10}{}\protected@file@percent }
\newlabel{tab:ablation_study}{{VI}{10}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Analysis of the performance contribution of each technical component in the ablation study. The chart quantitatively evaluates the contribution of GPR denoising, data augmentation techniques, and their combined scheme to the final classification accuracy.}}{10}{}\protected@file@percent }
\newlabel{fig:ablation_components}{{11}{10}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusion and Discussion}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VI-A}}Performance Analysis}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VI-B}}Main Contributions and Achievements}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VI-C}}Limitations of the Study}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {VII}Future Work}{11}{}\protected@file@percent }
\bibcite{dobre2007survey}{1}
\bibcite{hameed2009likelihood}{2}
\bibcite{hazza2013overview}{3}
\bibcite{oshea2016convolutional}{4}
\bibcite{west2017deep}{5}
\bibcite{rajendran2018deep}{6}
\bibcite{xu2025ldcvnn}{7}
\bibcite{ma2023hfecnetca}{8}
\bibcite{zhang2023efficient}{9}
\bibcite{patil2021automatic}{10}
\bibcite{xu2020spatiotemporal}{11}
\bibcite{yao2019modulation}{12}
\bibcite{ning2024abftnet}{13}
\bibcite{zhang2023amcnet}{14}
\bibcite{guo2024ulcnn}{15}
\bibcite{amcnet202x_meng}{16}
\@writefile{toc}{\contentsline {section}{References}{12}{}\protected@file@percent }
\gdef \@abspage@last{12}
